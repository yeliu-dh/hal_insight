
import streamlit as st
from streamlit_tags import st_tags
import pandas as pd
import matplotlib.pyplot as plt
from wordcloud import WordCloud, STOPWORDS
from PIL import Image
import io
import math

#my utils:
from utils.upload import csv_uploader

st.set_page_config(page_title="â˜ï¸ Wordcloud", page_icon="ðŸ›¸", layout="wide")
st.title("â˜ï¸ Wordcloud")


# -------------------------------
# 1ï¸âƒ£ åˆå§‹åŒ– Session State
# -------------------------------
if "uploaded_df" not in st.session_state:
    st.session_state.uploaded_df = None
if "started" not in st.session_state:
    st.session_state.started = False

# -------------------------------
# 2ï¸âƒ£ æ£€æŸ¥/ä¸Šä¼  CSV
# -------------------------------
csv_uploader()# è°ƒç”¨ä¸Šä¼ å™¨ï¼ˆä¼šè‡ªåŠ¨å¤„ç†å·²æœ‰/æ–°ä¸Šä¼ ï¼‰
if "uploaded_df" in st.session_state and st.session_state.uploaded_df is not None:

    # -------------------------------
    # 3ï¸âƒ£ ç‚¹å‡»å¼€å§‹ç»Ÿè®¡æŒ‰é’®
    # -------------------------------
    col1, col2, col3 = st.columns([4, 1, 1])  # æœ€å³è¾¹ä¸€åˆ—æ”¾æŒ‰é’®
    with col2:
        summary_button1 = st.button("Wordcloud global")
    
    with col3:
        summary_button2 = st.button("Wordcloud Ã©volutif")

    if not st.session_state.started:#æœªå¼€å§‹
        if summary_button1 or summary_button2:#ç‚¹å‡»äº†å¼€å§‹æŒ‰é’®
            # if st.session_state.uploaded_df is not None:#ä¸”å·²ç»ä¸Šä¼ æ•°æ®
            st.session_state.started = True#æ›´æ–°ä¸ºâ€œå¼€å§‹çŠ¶æ€â€ï¼Œdfå‚¨å­˜åœ¨sessionä¸­ï¼Œæ•°æ®ä¸ä¼šåœ¨å˜åŒ–?            
        
    # -------------------------------
    # # 4ï¸âƒ£ åˆ†æžç•Œé¢
    # # -------------------------------

    if st.session_state.started and summary_button1:
        df = st.session_state.uploaded_df.copy()

        # -------------------- å…³é”®è¯è¯äº‘ --------------------        
        # é€‰æ‹©æ–‡ç« èŒƒå›´
        option = st.radio("Choisir la granularitÃ© temporelle", ["keywords", "abstract"], horizontal=True)
        
        try:
            if option == "keywords" and "keyword_s" in df.columns:
                st.info(f"âš ï¸ Les mots clÃ©s sont manquants dans {df.keyword_s.isna().sum()} "
                        f"({df.keyword_s.isna().sum()*100/len(df):.2f}%) articles!")
                text = " ".join(df["keyword_s"].dropna().astype(str)).lower()

            elif option == "abstract" and "abstract_s" in df.columns:
                st.info(f"âš ï¸ Les rÃ©sumÃ©s sont manquants dans {df.abstract_s.isna().sum()} "
                        f"({df.abstract_s.isna().sum()*100/len(df):.2f}%) articles!")
                text = " ".join(df["abstract_s"].dropna().astype(str)).lower()

            else:
                st.warning("âš ï¸ La colonne sÃ©lectionnÃ©e n'existe pas dans le fichier CSV.")

        except Exception as e:
            st.error(f"âš ï¸ {e}")

        # --------------- max words ------------------
        max_words = st.number_input(
            "max_words:", 
            min_value=1, max_value=1000, value=100, step=1, key="max_words"
        )

        # ----------------- stopwords ---------------
        user_stopwords = st_tags(
            label="Ajouter des mots Ã  ignorer",
            text="Tapez un mot et appuyez sur EntrÃ©e",
            value=[],
            maxtags=50
        )
        french_stopwords = {"et", "de", "la", "le", "les","l","l'", "des", "un", "une", 
                            "du", "en", "au","d","dans","Ã ","par","pour","sur","sont","aux","au",
                            "leur","leurs","qui","ou","il","elle","ils","elles","je","tu","vous","nous","se",
                            "et","ce",'qui','que',"est","qu","avec","ont","ces",'celle','ceux','celles',
                            'comme','afin','ne',"son",'ses'}
        
        
        stopwords = set(STOPWORDS).union(french_stopwords).union(user_stopwords)

        # ------------ wordcloud ---------------------------
        wc = WordCloud(
            width=800,
            height=400,
            background_color="white",
            max_words=max_words,
            stopwords=stopwords,
            colormap="viridis"
        ).generate(text)

        st.image(wc.to_array(), use_container_width=True)

        # ------------------ ä¸‹è½½ PNG ------------------
        try:
            img = Image.fromarray(wc.to_array())
            buf = io.BytesIO()
            img.save(buf, format="PNG")
            buf.seek(0)

            cols = st.columns([5,1])  # 4:1 æ¯”ä¾‹ï¼Œå³ä¾§æ”¾æŒ‰é’®    
            with cols[1]:
                st.download_button(
                    label="TÃ©lÃ©charger",
                    data=buf,
                    file_name="worldcloud.png",
                    mime="image/png"
                )
        except Exception as e:
            st.error(f"ERROR :{e}")



    if st.session_state.started and summary_button2:
        df = st.session_state.uploaded_df.copy()
        df["publicationDate_s"] = pd.to_datetime(df["publicationDate_s"], errors="coerce")
        df["year"] = df["publicationDate_s"].dt.year

        # ---------------- ç”¨æˆ·è¾“å…¥ ----------------
        col1, col2, col3 = st.columns(3)
        with col1:
            start_year = st.number_input("AnnÃ©e de dÃ©but", min_value=1900, max_value=2100, value=2010)
        with col2:
            end_year = st.number_input("AnnÃ©e de fin", min_value=1900, max_value=2100, value=2020)
        with col3:
            step_year = st.number_input("Intervalle de temps", min_value=1, max_value=20, value=3)

        # ---------------- æ—¶é—´æ®µåˆ‡ç‰‡ ----------------
        time_slices = [(y, min(y + step_year - 1, end_year)) for y in range(start_year, end_year+1, step_year)]

        # ---------------- ç”Ÿæˆ keyness è¯äº‘ ----------------
        # è¿™é‡Œç¤ºä¾‹ç”¨ç®€å•é¢‘çŽ‡ä»£æ›¿ keyness
        # å¦‚æžœéœ€è¦ä¸¥æ ¼ keynessï¼Œå¯ç”¨ log-likelihood æˆ– chi-square

        texts_all = " ".join(df["keyword_s"].dropna().astype(str).str.lower())
        global_freq = pd.Series(texts_all.split()).value_counts()

        n_cols = 3
        n_rows = math.ceil(len(time_slices)/n_cols)
        fig, axes = plt.subplots(n_rows, n_cols, figsize=(n_cols*5, n_rows*5))

        for idx, (y_start, y_end) in enumerate(time_slices):
            df_slice = df[(df["year"] >= y_start) & (df["year"] <= y_end)]
            if df_slice.empty:
                text = ""
            else:
                text = " ".join(df_slice["keyword_s"].dropna().astype(str).str.lower())

            # ç®€å• keynessï¼šè¯é¢‘ / å…¨å±€è¯é¢‘
            freq_slice = pd.Series(text.split()).value_counts()
            keyness = (freq_slice / global_freq).fillna(0).to_dict()

            wc = WordCloud(width=400, height=400, background_color="white").generate_from_frequencies(keyness)

            row, col = divmod(idx, n_cols)
            ax = axes[row, col] if n_rows>1 else axes[col]
            ax.imshow(wc, interpolation="bilinear")
            ax.set_title(f"{y_start}-{y_end}", fontsize=12)
            ax.axis("off")

        # åˆ é™¤å¤šä½™å­å›¾
        for j in range(idx+1, n_rows*n_cols):
            row, col = divmod(j, n_cols)
            ax = axes[row, col] if n_rows>1 else axes[col]
            ax.axis("off")

        st.pyplot(fig)

